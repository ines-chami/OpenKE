{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdict_to_set(dict_r):\n",
    "    set_r = set()\n",
    "    for head in dict_r:\n",
    "        for tail in dict_r[head]:\n",
    "            set_r.add((head,tail))\n",
    "    return set_r\n",
    "\n",
    "def rdict_to_reverse_set(dict_r):\n",
    "    set_reverse_r = set()\n",
    "    for head in dict_r:\n",
    "        for tail in dict_r[head]:\n",
    "            set_reverse_r.add((tail,head))\n",
    "    return set_reverse_r\n",
    "\n",
    "def check_symmetric(r, all_relations,portion=0.9):\n",
    "    '''\n",
    "    input: r - a key in all_relations, representing a relation r\n",
    "    all_relations: a dict of relations, each relation is a dict of the form {h_1: [t_1, t_2, ...], h_2:[t_3,t_4,...]}\n",
    "    portion: similarity parameter, float\n",
    "    output: True or False\n",
    "    ---\n",
    "    check_symmetric will return True if for at least portion of the triplets (h,r,t) in relation r satisfy that \n",
    "    the triplet (t,r,h) also appears in r. Otherwise it returns False.\n",
    "    '''\n",
    "    if r in all_relations:\n",
    "        dict_r = all_relations[r]\n",
    "        set_r = rdict_to_set(dict_r)\n",
    "        set_reverse_r = rdict_to_reverse_set(dict_r)\n",
    "        if len(set_reverse_r.intersection(set_r)) >=portion*len(set_r):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_inversion(r, all_relations,portion=0.9):\n",
    "    '''\n",
    "    input: r - a key in all_relations, representing a relation r\n",
    "    all_relations: a dict of relations, each relation is a dict of the form {h_1: [t_1, t_2, ...], h_2:[t_3,t_4,...]}\n",
    "    portion: similarity parameter, float\n",
    "    output: None or an array of keys from all_relations\n",
    "    ---\n",
    "    check_inversion will return a key s if the relation s is an inverse of r for at least portion of the triplets in both.\n",
    "    otherwise it returns None.\n",
    "    '''\n",
    "    if r in all_relations:\n",
    "        r_inv=[]\n",
    "        dict_r = all_relations[r]\n",
    "        reversed_set_r = rdict_to_reverse_set(dict_r)\n",
    "        count_trip_r = len(reversed_set_r)\n",
    "        relations = all_relations.keys()\n",
    "        for s in relations:\n",
    "            dict_s = all_relations[s]\n",
    "            set_s = rdict_to_set(dict_s)\n",
    "            count_trip_s = len(set_s)\n",
    "            count_trip_intersection = len(set_s.intersection(reversed_set_r))\n",
    "            if count_trip_intersection >= portion*count_trip_s and count_trip_intersection>=portion*count_trip_r:\n",
    "                r_inv.append(s)\n",
    "        if len(r_inv)!=0:\n",
    "            return r_inv\n",
    "    return None\n",
    "\n",
    "def check_anti_sym(r, all_relations):\n",
    "    '''\n",
    "    input: r - a key in all_relations, representing a relation r\n",
    "    all_relations: a dict of relations, each relation is a dict of the form {h_1: [t_1, t_2, ...], h_2:[t_3,t_4,...]}\n",
    "    output: True or False\n",
    "    ---\n",
    "    check_anti_sym will return True if the relation r is antisymmetric\n",
    "    '''\n",
    "    if r in all_relations:\n",
    "        dict_r = all_relations[r]\n",
    "        set_r = rdict_to_set(dict_r)\n",
    "        reversed_set_r = rdict_to_reverse_set(dict_r)\n",
    "        if len(set_r.intersection(reversed_set_r))==0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_transitivity(r, all_relations, portion=0.9):\n",
    "    '''\n",
    "    input: r - a key in all_relations, representing a relation r\n",
    "    all_relations: a dict of relations, each relation is a dict of the form {h_1: [t_1, t_2, ...], h_2:[t_3,t_4,...]}\n",
    "    portion: float\n",
    "    output: True or False\n",
    "    ---\n",
    "    check_transitivity will return True if the relation r is transitive (in a non empty way) on at least portion of\n",
    "    the pairs of triplets (a,r,b) (b,r,c)\n",
    "    '''\n",
    "    if r in all_relations:\n",
    "        set_2_chain_endpoints = find_all_2_chains(all_relations[r])\n",
    "        set_r = rdict_to_set(all_relations[r])\n",
    "        if (len(set_2_chain_endpoints.intersection(set_r)) > portion*len(set_2_chain_endpoints) \n",
    "        and len(set_2_chain_endpoints.intersection(set_r)) > portion*0.05*len(set_r)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_all_2_chains(rdict):\n",
    "    set_2_chain_endpoints = set()\n",
    "    for a in rdict:\n",
    "        for b in rdict[a]:\n",
    "            if b in rdict:\n",
    "                for c in rdict[b]:\n",
    "                    set_2_chain_endpoints.add((a,c))\n",
    "    return set_2_chain_endpoints\n",
    "\n",
    "def check_composition(r, s, all_relations, chain_portion=0.8, portion=0.8):\n",
    "    '''\n",
    "    input:  r - a key in all_relations, representing a relation r\n",
    "            s - a key in all_relations, representing a relation s\n",
    "            all_relations: a dict of relations, each relation is a dict of the form \n",
    "            {h_1: [t_1, t_2, ...], h_2:[t_3,t_4,...]}\n",
    "            chain_portion: float\n",
    "            portion: float\n",
    "    output: None or a list of relations\n",
    "    ---\n",
    "    check_composition will return relations [u_1, u_2, ...] if applying r and then s is equivalent to applying \n",
    "    u = u_i, when at least \"chain_portion\" of the edges in r are composable and \"portion\" of the chains of length 2 \n",
    "    (a, r, b), (b, s, c) also appears in u as (a, u, c). If no such u is found, check_composition will return None.\n",
    "    '''\n",
    "    comp = []\n",
    "    if r in all_relations and s in all_relations:\n",
    "        dict_r = all_relations[r]\n",
    "        dict_s = all_relations[s]\n",
    "        two_chains = find_all_2_chains_two_rel(dict_r, dict_s)\n",
    "        if len(two_chains)>=chain_portion*(len(rdict_to_set(dict_r))):\n",
    "            for cand in all_relations:\n",
    "                set_cand = rdict_to_set(all_relations[cand])\n",
    "                if len(two_chains.intersection(set_cand)) >=portion*len(two_chains):\n",
    "                    comp.append(cand)\n",
    "        if len(comp)!=0:\n",
    "            return comp\n",
    "    return None\n",
    "\n",
    "        \n",
    "def find_all_2_chains_two_rel(rdict, sdict):\n",
    "    set_2_chain_endpoints = set()\n",
    "    for a in rdict:\n",
    "        for b in rdict[a]:\n",
    "            if b in sdict:\n",
    "                for c in sdict[b]:\n",
    "                    set_2_chain_endpoints.add((a,c))\n",
    "    return set_2_chain_endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"FB15K237\"\n",
    "train_file = \"../benchmarks/\" + dataset +\"/\"+ \"train2id.txt\"\n",
    "valid_file = \"../benchmarks/\" + dataset +\"/\"+ \"valid2id.txt\"\n",
    "test_file = \"../benchmarks/\" + dataset +\"/\"+ \"test2id.txt\"\n",
    "\n",
    "\n",
    "file = train_file\n",
    "triples = open(file, \"r\")\n",
    "\n",
    "all_relations_FB = dict()\n",
    "i=0\n",
    "\n",
    "for line in triples:\n",
    "    if i!=0:\n",
    "        h,t,r = list(map(int, line.strip().split()))\n",
    "        if r in all_relations_FB:\n",
    "            if h in all_relations_FB[r]:\n",
    "                all_relations_FB[r][h].append(t)\n",
    "            else:\n",
    "                all_relations_FB[r][h] = [t]\n",
    "        else:\n",
    "            all_relations_FB[r] = {h:[t]}\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sym = []\n",
    "list_of_inv = []\n",
    "list_of_anti_sym = []\n",
    "list_of_trans = []\n",
    "list_of_comp = []\n",
    "\n",
    "for r in all_relations_FB.keys():\n",
    "    if check_symmetric(r, all_relations_FB):\n",
    "        list_of_sym.append(r)\n",
    "    if check_inversion(r, all_relations_FB) is not None:\n",
    "        list_of_inv.append((r, check_inversion(r, all_relations_FB)))\n",
    "    if check_anti_sym(r, all_relations_FB):\n",
    "        list_of_anti_sym.append(r)    \n",
    "    if check_transitivity(r, all_relations_FB):\n",
    "        list_of_trans.append(r)\n",
    "    for s in all_relations_FB.keys():\n",
    "        check_comp_r_s=check_composition(r, s, all_relations_FB)\n",
    "        if check_comp_r_s is not None:\n",
    "            list_of_comp.append((r,s, check_comp_r_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_of_sym:  [56, 81, 146]\n",
      "list_of_inv:  [(56, [56]), (81, [81]), (146, [146])]\n",
      "list_of_anti_sym:  [0, 1, 2, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 55, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 117, 118, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 145, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 179, 181, 183, 184, 185, 186, 187, 189, 191, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 232, 233, 234, 236]\n",
      "list_of_trans:  [56, 81, 111, 146, 182, 190]\n",
      "list_of_comp:  [(16, 228, [16]), (56, 56, [56]), (56, 120, [120]), (81, 22, [22]), (81, 61, [61]), (81, 81, [81, 146]), (81, 101, [101]), (81, 124, [124]), (81, 146, [81, 146]), (108, 25, [25]), (111, 120, [120]), (128, 25, [25]), (146, 22, [22]), (146, 25, [25]), (146, 61, [61]), (146, 101, [101]), (146, 124, [124]), (146, 146, [146]), (166, 25, [25]), (175, 48, [48]), (217, 25, [25]), (225, 25, [25]), (228, 22, [22]), (228, 44, [44]), (228, 89, [89]), (228, 101, [101])]\n"
     ]
    }
   ],
   "source": [
    "print (\"list_of_sym: \", list_of_sym)\n",
    "print (\"list_of_inv: \", list_of_inv)\n",
    "print (\"list_of_anti_sym: \", list_of_anti_sym)\n",
    "print (\"list_of_trans: \", list_of_trans)\n",
    "print (\"list_of_comp: \", list_of_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "list_of_trans = []\n",
    "for r in all_relations_FB.keys():  \n",
    "    if check_transitivity(r, all_relations_FB, p):\n",
    "        list_of_trans.append(r)\n",
    "        \n",
    "print(list_of_trans)\n",
    "len(list_of_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean list_of_comp from id's\n",
    "ids = {56, 81, 146}\n",
    "\n",
    "cleaned_list_of_comp = []\n",
    "for item in list_of_comp:\n",
    "    r,s,_ = item\n",
    "    if r not in ids and s not in ids:\n",
    "        cleaned_list_of_comp.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 228, [16]),\n",
       " (108, 25, [25]),\n",
       " (111, 120, [120]),\n",
       " (128, 25, [25]),\n",
       " (166, 25, [25]),\n",
       " (175, 48, [48]),\n",
       " (217, 25, [25]),\n",
       " (225, 25, [25]),\n",
       " (228, 22, [22]),\n",
       " (228, 44, [44]),\n",
       " (228, 89, [89]),\n",
       " (228, 101, [101])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_list_of_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave # of edges for r:  212.83333333333334\n",
      "ave # of edges for s:  212.83333333333334\n",
      "ave # of two chain:  215.33333333333334\n",
      "ave # of two chain in intersection:  185.5\n",
      "ave # of edges for r_circ_s:  2623.3333333333335\n",
      "tot # of edges for r:  2554\n",
      "tot # of edges for s:  2554\n",
      "tot # of two chain:  2584\n",
      "tot # of two chain in intersection:  2226\n",
      "tot # of edges for r_circ_s:  31480\n"
     ]
    }
   ],
   "source": [
    "def total_num_edges_comp(cleaned_list_of_comp, all_relations):\n",
    "    total_edge_in_r = 0\n",
    "    total_edge_in_s = 0\n",
    "    total_two_chain = 0\n",
    "    total_two_chain_in_intersection = 0\n",
    "    total_edges_in_r_circ_s = 0\n",
    "    i=0\n",
    "    for item in cleaned_list_of_comp:\n",
    "        r,s,circ = item\n",
    "        circ = circ[0]\n",
    "        rset = rdict_to_set(all_relations[r])\n",
    "        total_edge_in_r+=len(rset)\n",
    "        sset = rdict_to_set(all_relations[r])\n",
    "        total_edge_in_s+=len(sset)\n",
    "        two_chain = find_all_2_chains_two_rel(all_relations[r],all_relations[s])\n",
    "        total_two_chain+=len(two_chain)\n",
    "        circ_set = rdict_to_set(all_relations[circ])\n",
    "        total_edges_in_r_circ_s+=len(circ_set)\n",
    "        total_two_chain_in_intersection+=len(two_chain.intersection(circ_set))\n",
    "        i+=1\n",
    "    \n",
    "    print(\"ave # of edges for r: \", total_edge_in_r/i)\n",
    "    print(\"ave # of edges for s: \", total_edge_in_s/i)\n",
    "    print(\"ave # of two chain: \", total_two_chain/i)\n",
    "    print(\"ave # of two chain in intersection: \", total_two_chain_in_intersection/i)\n",
    "    print(\"ave # of edges for r_circ_s: \", total_edges_in_r_circ_s/i)\n",
    "    \n",
    "    print(\"tot # of edges for r: \", total_edge_in_r)\n",
    "    print(\"tot # of edges for s: \", total_edge_in_s)\n",
    "    print(\"tot # of two chain: \", total_two_chain)\n",
    "    print(\"tot # of two chain in intersection: \", total_two_chain_in_intersection)\n",
    "    print(\"tot # of edges for r_circ_s: \", total_edges_in_r_circ_s)\n",
    "\n",
    "total_num_edges_comp(cleaned_list_of_comp, all_relations_FB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_of_sym:  [1, 9, 10]\n",
      "list_of_anti_sym:  [0, 2, 4, 6, 7, 8]\n",
      "list_of_inv:  [(1, [1]), (9, [9]), (10, [10])]\n",
      "list_of_comp:  []\n",
      "list_of_trans:  []\n",
      "len list_of_sym:  3\n",
      "len list_of_anti_sym:  6\n",
      "len list_of_inv:  3\n",
      "len list_of_comp:  0\n",
      "len list_of_trans:  0\n"
     ]
    }
   ],
   "source": [
    "dataset = \"WN18RR\"\n",
    "train_file = \"../benchmarks/\" + dataset +\"/\"+ \"train2id.txt\"\n",
    "valid_file = \"../benchmarks/\" + dataset +\"/\"+ \"valid2id.txt\"\n",
    "test_file = \"../benchmarks/\" + dataset +\"/\"+ \"test2id.txt\"\n",
    "\n",
    "\n",
    "file = train_file\n",
    "triples = open(file, \"r\")\n",
    "\n",
    "all_relations = dict()\n",
    "i=0\n",
    "\n",
    "for line in triples:\n",
    "    if i!=0:\n",
    "        h,t,r = list(map(int, line.strip().split()))\n",
    "        if r in all_relations:\n",
    "            if h in all_relations[r]:\n",
    "                all_relations[r][h].append(t)\n",
    "            else:\n",
    "                all_relations[r][h] = [t]\n",
    "        else:\n",
    "            all_relations[r] = {h:[t]}\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "list_of_sym_wn = []\n",
    "list_of_inv_wn = []\n",
    "list_of_anti_sym_wn = []\n",
    "list_of_trans_wn = []\n",
    "list_of_comp_wn = []\n",
    "\n",
    "for r in all_relations.keys():\n",
    "    if check_symmetric(r, all_relations):\n",
    "        list_of_sym_wn.append(r)\n",
    "    if check_inversion(r, all_relations) is not None:\n",
    "        list_of_inv_wn.append((r, check_inversion(r, all_relations)))\n",
    "    if check_anti_sym(r, all_relations):\n",
    "        list_of_anti_sym_wn.append(r)    \n",
    "    if check_transitivity(r, all_relations):\n",
    "        list_of_trans_wn.append(r)\n",
    "    for s in all_relations.keys():\n",
    "        check_comp_r_s=check_composition(r, s, all_relations)\n",
    "        if check_comp_r_s is not None:\n",
    "            list_of_comp_wn.append((r,s, check_comp_r_s))\n",
    "\n",
    "            \n",
    "print (\"list_of_sym: \", list_of_sym_wn)\n",
    "print (\"list_of_anti_sym: \", list_of_anti_sym_wn)\n",
    "print (\"list_of_inv: \", list_of_inv_wn)\n",
    "print (\"list_of_comp: \", list_of_comp_wn)\n",
    "print (\"list_of_trans: \", list_of_trans_wn)\n",
    "\n",
    "\n",
    "\n",
    "print (\"len list_of_sym: \", len(list_of_sym_wn))\n",
    "print (\"len list_of_anti_sym: \", len(list_of_anti_sym_wn))\n",
    "print (\"len list_of_inv: \", len(list_of_inv_wn))\n",
    "print (\"len list_of_comp: \", len(list_of_comp_wn))\n",
    "print (\"len list_of_trans: \",  len(list_of_trans_wn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_num_edges(list_of_rel, all_relations):\n",
    "    total = 0\n",
    "    for r in list_of_rel:\n",
    "        total+=len(rdict_to_set(all_relations[r]))\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_set_for_rel_type(list_of_rel,test_file_loc, dst):\n",
    "    #written in the same format as test2id.txt\n",
    "    test_all_file = open(test_file_loc, 'r') \n",
    "    test_all = test_all_file.readlines()\n",
    "    test_all_file.close()\n",
    "    lines_to_remove = []\n",
    "    for i in range(len(test_all)):\n",
    "        if i!=0:\n",
    "            h,t,r = list(map(int, test_all[i].strip().split()))\n",
    "            if r not in list_of_rel:\n",
    "                lines_to_remove.append(test_all[i])\n",
    "    for line in lines_to_remove:\n",
    "        test_all.remove(line)\n",
    "    test_all[0] = str(len(test_all)-1) + \"\\n\"\n",
    "    with open(dst, 'w') as f:\n",
    "        for item in test_all:\n",
    "            f.write(\"%s\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"WN18RR\"\n",
    "test_file = \"../benchmarks/\" + dataset +\"/\"+ \"test2id.txt\"\n",
    "new_test_file = \"../benchmarks/\" + dataset +\"/\"+ \"symtest2id.txt\"\n",
    "list_of_rel = list_of_sym_wn\n",
    "generate_test_set_for_rel_type(list_of_rel, test_file, new_test_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_file = \"../benchmarks/\" + dataset +\"/\"+ \"antitest2id.txt\"\n",
    "list_of_rel = list_of_anti_sym_wn\n",
    "generate_test_set_for_rel_type(list_of_rel, test_file, new_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_rest(list_of_sym, list_of_anti_sym, num_of_relation):\n",
    "    rest = []\n",
    "    for i in range(num_of_relation):\n",
    "        if (i not in list_of_sym) and (i not in list_of_anti_sym):\n",
    "            rest.append(i)\n",
    "    return rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_wn = list_of_rest(list_of_sym_wn, list_of_anti_sym_wn, 11)\n",
    "rest_wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_file = \"../benchmarks/\" + dataset +\"/\"+ \"resttest2id.txt\"\n",
    "list_of_rel = rest_wn\n",
    "generate_test_set_for_rel_type(list_of_rel, test_file, new_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"FB15K237\"\n",
    "test_file = \"../benchmarks/\" + dataset +\"/\"+ \"test2id.txt\"\n",
    "new_test_file = \"../benchmarks/\" + dataset +\"/\"+ \"symtest2id.txt\"\n",
    "list_of_rel = list_of_sym\n",
    "generate_test_set_for_rel_type(list_of_rel, test_file, new_test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_file = \"../benchmarks/\" + dataset +\"/\"+ \"antitest2id.txt\"\n",
    "list_of_rel = list_of_anti_sym\n",
    "generate_test_set_for_rel_type(list_of_rel, test_file, new_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = list_of_rest(list_of_sym, list_of_anti_sym, 237)\n",
    "\n",
    "new_test_file = \"../benchmarks/\" + dataset +\"/\"+ \"resttest2id.txt\"\n",
    "list_of_rel = rest\n",
    "generate_test_set_for_rel_type(list_of_rel, test_file, new_test_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgemb19",
   "language": "python",
   "name": "kgemb19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
